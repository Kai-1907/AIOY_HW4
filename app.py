import os
import streamlit as st
import tensorflow as tf
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
import numpy as np
from PIL import Image
import streamlit as st


import requests
import json

# ================= 1. é…ç½® AIGC Agent (ç›´æ¥ä½¿ç”¨ API) =================
def generate_food_report(food_name):
    api_key = st.secrets["GEMINI_API_KEY"]
    # ç›´æ¥ä½¿ç”¨æ­£å¼ç‰ˆ v1 API è·¯å¾‘ï¼Œé¿é–‹ SDK çš„ v1beta éŒ¯èª¤
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={api_key}"
    
    headers = {'Content-Type': 'application/json'}
    payload = {
        "contents": [{
            "parts": [{
                "text": f"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¾é£Ÿè©•è«–å®¶ã€‚å½±åƒè¾¨è­˜æ¨¡å‹åˆ¤æ–·é€™æ˜¯ä¸€ä»½ã€Œ{food_name}ã€ã€‚è«‹ç”¨ 100 å­—ä»¥å…§ä»‹ç´¹å®ƒçš„ç‰¹è‰²ï¼Œä¸¦åˆ—å‡ºä¸»è¦ç‡Ÿé¤Šæˆåˆ†ã€‚"
            }]
        }]
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        result = response.json()
        # å–å¾—å›å‚³çš„æ–‡å­—å…§å®¹
        return result['candidates'][0]['content']['parts'][0]['text']
    except Exception as e:
        return f"AI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼š{str(e)}"



# ================= 2. è¼‰å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹ (æ–¹æ³•ä¸€) =================
@st.cache_resource
def load_dl_model():
    # ä½¿ç”¨ MobileNetV2ï¼Œé è¨“ç·´æ¬Šé‡ç‚º imagenet
    return MobileNetV2(weights='imagenet')

model = load_dl_model()

# ================= 3. Streamlit ä»‹é¢è¨­è¨ˆ =================
st.title("ğŸ” Taica AIGC èª²ç¨‹å°ˆé¡Œï¼šé£Ÿç‰©è¾¨è­˜æ™ºèƒ½ Agent")
st.write("ä¸Šå‚³ä¸€å¼µé£Ÿç‰©ç…§ç‰‡ï¼Œæ·±åº¦å­¸ç¿’æ¨¡å‹å°‡é€²è¡Œè¾¨è­˜ï¼Œä¸¦ç”± AI Agent æ’°å¯«è©•è«–ã€‚")

uploaded_file = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–ç‰‡...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # é¡¯ç¤ºåœ–ç‰‡
    img = Image.open(uploaded_file)
    st.image(img, caption='ä¸Šå‚³çš„åœ–ç‰‡', use_container_width=True)
    
    # å½±åƒé è™•ç†
    # 1. å¼·åˆ¶è½‰ç‚º RGB (é¿å… PNG çš„ 4 é€šé“å•é¡Œ)
    img_rgb = img.convert('RGB')
    
    # 2. èª¿æ•´å¤§å°ç‚º MobileNetV2 è¦æ±‚çš„ 224x224
    img_resized = img_rgb.resize((224, 224))
    
    # 3. è½‰ç‚º Numpy é™£åˆ—
    x = image.img_to_array(img_resized)
    
    # 4. å¢åŠ æ‰¹æ¬¡ç¶­åº¦ï¼Œå¾ (224, 224, 3) è®Šæˆ (1, 224, 224, 3)
    x = np.expand_dims(x, axis=0)
    
    # 5. åŸ·è¡Œ MobileNetV2 çš„å°ˆå±¬é è™•ç† (åŒ…å«æ•¸å€¼ç¸®æ”¾)
    x = preprocess_input(x)

    # åŸ·è¡Œè¾¨è­˜
    with st.spinner('æ·±åº¦å­¸ç¿’æ¨¡å‹è¾¨è­˜ä¸­...'):
        preds = model.predict(x)
        # å–å¾—æœ€é«˜æ©Ÿç‡çš„çµæœ (Label)
        results = decode_predictions(preds, top=1)[0]
        food_name_en = results[0][1] # å–å¾—è‹±æ–‡åç¨±
        confidence = results[0][2]

    st.success(f"è¾¨è­˜çµæœï¼š{food_name_en} (ä¿¡å¿ƒåº¦: {confidence:.2%})")

    # åŸ·è¡Œ Agent å»¶ä¼¸åŠŸèƒ½
    st.divider()
    st.subheader("ğŸ¤– AI Agent å»¶ä¼¸å ±å‘Š")
    with st.spinner('Agent æ­£åœ¨æ’°å¯«æ–‡æ¡ˆ...'):
        # é€™è£¡å¯ä»¥åŠ å…¥ä¸€å€‹ç°¡å–®çš„ç¿»è­¯æˆ–ç›´æ¥æŠŠè‹±æ–‡åçµ¦ LLM
        report = generate_food_report(food_name_en)
        st.write(report)

st.divider()
st.caption("åƒè€ƒä¾†æºï¼šTaica AIGC èª²ç¨‹å¯¦ä½œ | æ¨¡å‹ï¼šMobileNetV2 | éƒ¨ç½²ï¼šStreamlit")